{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d66f1e8",
   "metadata": {},
   "source": [
    "# üìä NEPSE Floor Sheet Analysis Dashboard\n",
    "\n",
    "## üéØ Market Manipulation & Broker Activity Detection\n",
    "\n",
    "This comprehensive analysis tool helps identify suspicious trading patterns and broker activities in the Nepal Stock Exchange (NEPSE) floor sheet data.\n",
    "\n",
    "### üîç Analysis Features:\n",
    "- **üö® Broker Dominance Detection**: Identify when single brokers control large volumes\n",
    "- **üîÑ Wash Trading Detection**: Spot same brokers on both buy/sell sides\n",
    "- **üìà Volume Surge Analysis**: Track unusual volume spikes and responsible brokers\n",
    "- **üí∞ Aggressive Buying Detection**: Find brokers consistently buying at higher prices\n",
    "- **üìã Net Holdings Analysis**: Track broker positions and share turnover\n",
    "\n",
    "### ‚è∞ Timeframe Options:\n",
    "Daily | Weekly | Monthly | Quarterly | Yearly | 15-Day Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa62e3d0",
   "metadata": {},
   "source": [
    "## üìö Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìä Ready for NEPSE Floor Sheet Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a3437",
   "metadata": {},
   "source": [
    "## üìÇ Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ff225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_floorsheet_data(data_path='data/'):\n",
    "    \"\"\"\n",
    "    Load all floor sheet CSV files from the data directory\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get all CSV files in the data directory\n",
    "        csv_files = glob.glob(os.path.join(data_path, \"*.csv\"))\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(\"‚ùå No CSV files found in the data directory!\")\n",
    "            print(\"Please run the scraper first: python scrape_floorsheet.py\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(f\"üìÅ Found {len(csv_files)} CSV files\")\n",
    "        \n",
    "        # Load and combine all CSV files\n",
    "        dataframes = []\n",
    "        for file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                # Extract date from filename\n",
    "                filename = os.path.basename(file)\n",
    "                if 'nepal_stock_floorsheet_' in filename:\n",
    "                    date_str = filename.replace('nepal_stock_floorsheet_', '').replace('.csv', '')\n",
    "                    df['Date'] = date_str\n",
    "                dataframes.append(df)\n",
    "                print(f\"‚úÖ Loaded: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {file}: {str(e)}\")\n",
    "        \n",
    "        if not dataframes:\n",
    "            print(\"‚ùå No valid data found!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Combine all dataframes\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        \n",
    "        # Clean and standardize column names\n",
    "        combined_df.columns = combined_df.columns.str.strip()\n",
    "        \n",
    "        return combined_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in load_floorsheet_data: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load the data\n",
    "print(\"üîÑ Loading floor sheet data...\")\n",
    "df = load_floorsheet_data()\n",
    "\n",
    "if not df.empty:\n",
    "    print(f\"‚úÖ Successfully loaded {len(df)} records\")\n",
    "    print(f\"üìä Data shape: {df.shape}\")\n",
    "    print(f\"üìÖ Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"‚ùå No data loaded. Please check your data directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1218656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess the floor sheet data\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    try:\n",
    "        # Convert Date column to datetime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # Clean numeric columns\n",
    "        numeric_columns = ['Quantity', 'Rate (Rs)', 'Amount (Rs)']\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # Remove rows with missing critical data\n",
    "        df = df.dropna(subset=['Stock Symbol', 'Buyer', 'Seller'])\n",
    "        \n",
    "        # Add time-based columns for analysis\n",
    "        df['Year'] = df['Date'].dt.year\n",
    "        df['Quarter'] = df['Date'].dt.quarter\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['Week'] = df['Date'].dt.isocalendar().week\n",
    "        df['DayOfYear'] = df['Date'].dt.dayofyear\n",
    "        \n",
    "        # Add period columns for easy filtering\n",
    "        df['YearQuarter'] = df['Year'].astype(str) + '-Q' + df['Quarter'].astype(str)\n",
    "        df['YearMonth'] = df['Date'].dt.to_period('M').astype(str)\n",
    "        df['YearWeek'] = df['Date'].dt.to_period('W').astype(str)\n",
    "        \n",
    "        print(\"‚úÖ Data preprocessing completed\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in preprocessing: {str(e)}\")\n",
    "        return df\n",
    "\n",
    "def get_timeframe_data(df, timeframe, periods_back=0):\n",
    "    \"\"\"\n",
    "    Filter data based on selected timeframe\n",
    "    timeframe options: 'daily', 'weekly', 'monthly', 'quarterly', 'yearly', '15days'\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    today = df['Date'].max()\n",
    "    \n",
    "    if timeframe == 'daily':\n",
    "        start_date = today - timedelta(days=periods_back)\n",
    "        filtered_df = df[df['Date'] == start_date]\n",
    "    elif timeframe == '15days':\n",
    "        start_date = today - timedelta(days=15 + periods_back*15)\n",
    "        end_date = today - timedelta(days=periods_back*15)\n",
    "        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    elif timeframe == 'weekly':\n",
    "        start_date = today - timedelta(weeks=1 + periods_back)\n",
    "        end_date = today - timedelta(weeks=periods_back)\n",
    "        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    elif timeframe == 'monthly':\n",
    "        start_date = today - pd.DateOffset(months=1 + periods_back)\n",
    "        end_date = today - pd.DateOffset(months=periods_back)\n",
    "        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    elif timeframe == 'quarterly':\n",
    "        start_date = today - pd.DateOffset(months=3 + periods_back*3)\n",
    "        end_date = today - pd.DateOffset(months=periods_back*3)\n",
    "        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    elif timeframe == 'yearly':\n",
    "        start_date = today - pd.DateOffset(years=1 + periods_back)\n",
    "        end_date = today - pd.DateOffset(years=periods_back)\n",
    "        filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Preprocess the loaded data\n",
    "if not df.empty:\n",
    "    df = preprocess_data(df)\n",
    "    print(f\"‚úÖ Preprocessed data ready with {len(df)} records\")\n",
    "    print(f\"üìà Available stocks: {sorted(df['Stock Symbol'].unique())}\")\n",
    "else:\n",
    "    print(\"‚ùå No data to preprocess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3946ff8",
   "metadata": {},
   "source": [
    "## üö® 1. Broker Dominance Detection\n",
    "\n",
    "**What it detects:** Single brokers controlling large portions of a stock's trading volume\n",
    "**Why it matters:** May indicate market manipulation or artificial price movements\n",
    "**Threshold:** Flags brokers with >60-80% of total volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e670c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_broker_dominance(df, stock_symbol=None, timeframe='daily', threshold=60):\n",
    "    \"\"\"\n",
    "    Analyze broker dominance for a specific stock and timeframe\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    # Filter data\n",
    "    if stock_symbol:\n",
    "        stock_data = df[df['Stock Symbol'] == stock_symbol]\n",
    "    else:\n",
    "        stock_data = df\n",
    "    \n",
    "    stock_data = get_timeframe_data(stock_data, timeframe)\n",
    "    \n",
    "    if stock_data.empty:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Group by stock symbol if analyzing multiple stocks\n",
    "    for symbol in stock_data['Stock Symbol'].unique():\n",
    "        symbol_data = stock_data[stock_data['Stock Symbol'] == symbol]\n",
    "        \n",
    "        # Calculate total volume for the stock\n",
    "        total_volume = symbol_data['Quantity'].sum()\n",
    "        \n",
    "        # Calculate volume per buyer broker\n",
    "        buyer_volume = symbol_data.groupby('Buyer')['Quantity'].agg(['sum', 'count']).reset_index()\n",
    "        buyer_volume.columns = ['Broker', 'Volume', 'Trades']\n",
    "        buyer_volume['Percentage'] = (buyer_volume['Volume'] / total_volume) * 100\n",
    "        buyer_volume['Side'] = 'Buyer'\n",
    "        buyer_volume['Stock'] = symbol\n",
    "        \n",
    "        # Calculate volume per seller broker\n",
    "        seller_volume = symbol_data.groupby('Seller')['Quantity'].agg(['sum', 'count']).reset_index()\n",
    "        seller_volume.columns = ['Broker', 'Volume', 'Trades']\n",
    "        seller_volume['Percentage'] = (seller_volume['Volume'] / total_volume) * 100\n",
    "        seller_volume['Side'] = 'Seller'\n",
    "        seller_volume['Stock'] = symbol\n",
    "        \n",
    "        # Combine buyer and seller data\n",
    "        all_brokers = pd.concat([buyer_volume, seller_volume], ignore_index=True)\n",
    "        \n",
    "        # Flag suspicious brokers\n",
    "        all_brokers['Suspicious'] = all_brokers['Percentage'] >= threshold\n",
    "        all_brokers['Total_Stock_Volume'] = total_volume\n",
    "        \n",
    "        results.append(all_brokers)\n",
    "    \n",
    "    if results:\n",
    "        final_results = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary = {\n",
    "            'total_records': len(final_results),\n",
    "            'suspicious_brokers': len(final_results[final_results['Suspicious']]),\n",
    "            'max_dominance': final_results['Percentage'].max(),\n",
    "            'avg_dominance': final_results['Percentage'].mean(),\n",
    "            'stocks_analyzed': final_results['Stock'].nunique()\n",
    "        }\n",
    "        \n",
    "        return final_results.sort_values('Percentage', ascending=False), summary\n",
    "    \n",
    "    return pd.DataFrame(), {}\n",
    "\n",
    "def display_dominance_analysis(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Display broker dominance analysis with visualizations\n",
    "    \"\"\"\n",
    "    results, summary = analyze_broker_dominance(df, stock_symbol, timeframe)\n",
    "    \n",
    "    if results.empty:\n",
    "        print(\"‚ùå No data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä BROKER DOMINANCE ANALYSIS - {timeframe.upper()}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üìà Stocks Analyzed: {summary['stocks_analyzed']}\")\n",
    "    print(f\"üö® Suspicious Brokers Found: {summary['suspicious_brokers']}\")\n",
    "    print(f\"üìä Maximum Dominance: {summary['max_dominance']:.2f}%\")\n",
    "    print(f\"üìä Average Dominance: {summary['avg_dominance']:.2f}%\")\n",
    "    \n",
    "    # Show suspicious brokers\n",
    "    suspicious = results[results['Suspicious']]\n",
    "    if not suspicious.empty:\n",
    "        print(\"\\nüö® SUSPICIOUS BROKERS (>60% dominance):\")\n",
    "        display(suspicious[['Stock', 'Broker', 'Side', 'Volume', 'Percentage', 'Trades']].round(2))\n",
    "        \n",
    "        # Create visualization\n",
    "        fig = px.bar(suspicious.head(10), \n",
    "                    x='Broker', y='Percentage', \n",
    "                    color='Side', facet_col='Stock',\n",
    "                    title='Top 10 Dominant Brokers by Stock',\n",
    "                    labels={'Percentage': 'Volume Dominance (%)'})\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No suspicious broker dominance detected\")\n",
    "    \n",
    "    # Show top brokers overall\n",
    "    print(f\"\\nüìä TOP 10 BROKERS BY VOLUME:\")\n",
    "    top_brokers = results.head(10)[['Stock', 'Broker', 'Side', 'Volume', 'Percentage', 'Trades']].round(2)\n",
    "    display(top_brokers)\n",
    "\n",
    "# Example usage (uncomment to run with your data)\n",
    "# if not df.empty:\n",
    "#     display_dominance_analysis(df, timeframe='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89591f9",
   "metadata": {},
   "source": [
    "## üîÑ 2. Wash Trading Detection\n",
    "\n",
    "**What it detects:** Same brokers appearing on both buy and sell sides, or broker pairs trading repeatedly\n",
    "**Why it matters:** May indicate illegal wash trading or market manipulation\n",
    "**Red flags:** Same broker IDs, repetitive broker pairs, circular trading patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_wash_trading(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Detect potential wash trading patterns\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}\n",
    "    \n",
    "    # Filter data\n",
    "    if stock_symbol:\n",
    "        stock_data = df[df['Stock Symbol'] == stock_symbol]\n",
    "    else:\n",
    "        stock_data = df\n",
    "    \n",
    "    stock_data = get_timeframe_data(stock_data, timeframe)\n",
    "    \n",
    "    if stock_data.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}\n",
    "    \n",
    "    # 1. Same broker on both sides (exact same broker ID)\n",
    "    same_broker_trades = stock_data[stock_data['Buyer'] == stock_data['Seller']]\n",
    "    \n",
    "    # 2. Broker pairs trading repeatedly\n",
    "    stock_data['Broker_Pair'] = stock_data[['Buyer', 'Seller']].apply(\n",
    "        lambda x: '-'.join(sorted([str(x['Buyer']), str(x['Seller'])])), axis=1\n",
    "    )\n",
    "    \n",
    "    # Count trades per broker pair\n",
    "    pair_counts = stock_data.groupby(['Stock Symbol', 'Broker_Pair']).agg({\n",
    "        'Quantity': ['sum', 'count'],\n",
    "        'Amount (Rs)': 'sum',\n",
    "        'Rate (Rs)': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    pair_counts.columns = ['Stock', 'Broker_Pair', 'Total_Volume', 'Trade_Count', 'Total_Amount', 'Avg_Rate']\n",
    "    \n",
    "    # Flag suspicious pairs (more than 5 trades or high volume)\n",
    "    suspicious_pairs = pair_counts[\n",
    "        (pair_counts['Trade_Count'] >= 5) | \n",
    "        (pair_counts['Total_Volume'] >= stock_data['Quantity'].quantile(0.9))\n",
    "    ].sort_values('Trade_Count', ascending=False)\n",
    "    \n",
    "    # Summary statistics\n",
    "    summary = {\n",
    "        'same_broker_trades': len(same_broker_trades),\n",
    "        'suspicious_pairs': len(suspicious_pairs),\n",
    "        'total_broker_pairs': len(pair_counts),\n",
    "        'max_pair_trades': pair_counts['Trade_Count'].max() if not pair_counts.empty else 0\n",
    "    }\n",
    "    \n",
    "    return same_broker_trades, suspicious_pairs, summary\n",
    "\n",
    "def display_wash_trading_analysis(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Display wash trading analysis with visualizations\n",
    "    \"\"\"\n",
    "    same_broker, suspicious_pairs, summary = detect_wash_trading(df, stock_symbol, timeframe)\n",
    "    \n",
    "    print(f\"üîÑ WASH TRADING ANALYSIS - {timeframe.upper()}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üö® Same Broker Trades: {summary['same_broker_trades']}\")\n",
    "    print(f\"üîÑ Suspicious Broker Pairs: {summary['suspicious_pairs']}\")\n",
    "    print(f\"üìä Total Broker Pairs: {summary['total_broker_pairs']}\")\n",
    "    print(f\"üìà Max Trades per Pair: {summary['max_pair_trades']}\")\n",
    "    \n",
    "    # Show same broker trades\n",
    "    if not same_broker.empty:\n",
    "        print(\"\\nüö® SAME BROKER ON BOTH SIDES:\")\n",
    "        display(same_broker[['Date', 'Stock Symbol', 'Buyer', 'Seller', 'Quantity', 'Rate (Rs)', 'Amount (Rs)']].head(10))\n",
    "        \n",
    "        # Visualization for same broker trades\n",
    "        same_broker_summary = same_broker.groupby('Stock Symbol')['Quantity'].sum().reset_index()\n",
    "        if not same_broker_summary.empty:\n",
    "            fig = px.bar(same_broker_summary, \n",
    "                        x='Stock Symbol', y='Quantity',\n",
    "                        title='Volume of Same-Broker Trades by Stock')\n",
    "            fig.show()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No same-broker trades detected\")\n",
    "    \n",
    "    # Show suspicious pairs\n",
    "    if not suspicious_pairs.empty:\n",
    "        print(f\"\\nüîÑ SUSPICIOUS BROKER PAIRS:\")\n",
    "        display(suspicious_pairs.head(10))\n",
    "        \n",
    "        # Visualization for broker pairs\n",
    "        fig = px.scatter(suspicious_pairs.head(20), \n",
    "                        x='Trade_Count', y='Total_Volume', \n",
    "                        color='Stock', size='Total_Amount',\n",
    "                        title='Suspicious Broker Pairs - Trade Frequency vs Volume',\n",
    "                        hover_data=['Broker_Pair'])\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No suspicious broker pairs detected\")\n",
    "\n",
    "# Example usage (uncomment to run with your data)\n",
    "# if not df.empty:\n",
    "#     display_wash_trading_analysis(df, timeframe='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fd275",
   "metadata": {},
   "source": [
    "## üìà 3. Volume Surge & Broker Activity Analysis\n",
    "\n",
    "**What it detects:** Unusual volume spikes and which brokers are responsible\n",
    "**Why it matters:** Sudden volume surges often precede price manipulation\n",
    "**Analysis:** Compares current volume vs 10-day average, identifies new active brokers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_volume_surge(df, stock_symbol=None, surge_threshold=2.0):\n",
    "    \"\"\"\n",
    "    Analyze volume surges and responsible brokers\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    # Filter for specific stock if provided\n",
    "    if stock_symbol:\n",
    "        stock_data = df[df['Stock Symbol'] == stock_symbol]\n",
    "    else:\n",
    "        stock_data = df\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for symbol in stock_data['Stock Symbol'].unique():\n",
    "        symbol_data = stock_data[stock_data['Stock Symbol'] == symbol].copy()\n",
    "        symbol_data = symbol_data.sort_values('Date')\n",
    "        \n",
    "        # Calculate daily volume\n",
    "        daily_volume = symbol_data.groupby('Date')['Quantity'].sum().reset_index()\n",
    "        daily_volume['Stock'] = symbol\n",
    "        \n",
    "        # Calculate 10-day rolling average\n",
    "        daily_volume['Volume_10day_avg'] = daily_volume['Quantity'].rolling(window=10, min_periods=1).mean()\n",
    "        daily_volume['Volume_Ratio'] = daily_volume['Quantity'] / daily_volume['Volume_10day_avg']\n",
    "        \n",
    "        # Identify surge days\n",
    "        surge_days = daily_volume[daily_volume['Volume_Ratio'] >= surge_threshold]\n",
    "        \n",
    "        # For each surge day, identify responsible brokers\n",
    "        for _, surge_day in surge_days.iterrows():\n",
    "            surge_date = surge_day['Date']\n",
    "            surge_trades = symbol_data[symbol_data['Date'] == surge_date]\n",
    "            \n",
    "            # Analyze broker activity on surge day\n",
    "            buyer_activity = surge_trades.groupby('Buyer')['Quantity'].sum().reset_index()\n",
    "            buyer_activity.columns = ['Broker', 'Volume']\n",
    "            buyer_activity['Side'] = 'Buyer'\n",
    "            buyer_activity['Date'] = surge_date\n",
    "            buyer_activity['Stock'] = symbol\n",
    "            buyer_activity['Volume_Ratio'] = surge_day['Volume_Ratio']\n",
    "            buyer_activity['Total_Day_Volume'] = surge_day['Quantity']\n",
    "            buyer_activity['Broker_Percentage'] = (buyer_activity['Volume'] / surge_day['Quantity']) * 100\n",
    "            \n",
    "            seller_activity = surge_trades.groupby('Seller')['Quantity'].sum().reset_index()\n",
    "            seller_activity.columns = ['Broker', 'Volume']\n",
    "            seller_activity['Side'] = 'Seller'\n",
    "            seller_activity['Date'] = surge_date\n",
    "            seller_activity['Stock'] = symbol\n",
    "            seller_activity['Volume_Ratio'] = surge_day['Volume_Ratio']\n",
    "            seller_activity['Total_Day_Volume'] = surge_day['Quantity']\n",
    "            seller_activity['Broker_Percentage'] = (seller_activity['Volume'] / surge_day['Quantity']) * 100\n",
    "            \n",
    "            # Check for new brokers (brokers not active in previous 10 days)\n",
    "            prev_10_days = symbol_data[\n",
    "                (symbol_data['Date'] >= surge_date - timedelta(days=10)) & \n",
    "                (symbol_data['Date'] < surge_date)\n",
    "            ]\n",
    "            \n",
    "            prev_buyers = set(prev_10_days['Buyer'].unique())\n",
    "            prev_sellers = set(prev_10_days['Seller'].unique())\n",
    "            \n",
    "            buyer_activity['New_Broker'] = ~buyer_activity['Broker'].isin(prev_buyers)\n",
    "            seller_activity['New_Broker'] = ~seller_activity['Broker'].isin(prev_sellers)\n",
    "            \n",
    "            results.extend([buyer_activity, seller_activity])\n",
    "    \n",
    "    if results:\n",
    "        final_results = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        summary = {\n",
    "            'surge_days': len(final_results['Date'].unique()),\n",
    "            'avg_surge_ratio': final_results['Volume_Ratio'].mean(),\n",
    "            'max_surge_ratio': final_results['Volume_Ratio'].max(),\n",
    "            'new_brokers_count': len(final_results[final_results['New_Broker']]),\n",
    "            'stocks_with_surges': final_results['Stock'].nunique()\n",
    "        }\n",
    "        \n",
    "        return final_results, summary\n",
    "    \n",
    "    return pd.DataFrame(), {}\n",
    "\n",
    "def display_volume_surge_analysis(df, stock_symbol=None):\n",
    "    \"\"\"\n",
    "    Display volume surge analysis with visualizations\n",
    "    \"\"\"\n",
    "    results, summary = analyze_volume_surge(df, stock_symbol)\n",
    "    \n",
    "    if results.empty:\n",
    "        print(\"‚ùå No volume surge data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìà VOLUME SURGE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üìä Surge Days Detected: {summary['surge_days']}\")\n",
    "    print(f\"üìà Average Surge Ratio: {summary['avg_surge_ratio']:.2f}x\")\n",
    "    print(f\"üöÄ Maximum Surge Ratio: {summary['max_surge_ratio']:.2f}x\")\n",
    "    print(f\"üÜï New Brokers in Surges: {summary['new_brokers_count']}\")\n",
    "    print(f\"üìä Stocks with Surges: {summary['stocks_with_surges']}\")\n",
    "    \n",
    "    # Show biggest surges\n",
    "    biggest_surges = results.sort_values('Volume_Ratio', ascending=False).drop_duplicates(['Date', 'Stock']).head(10)\n",
    "    print(f\"\\nüöÄ BIGGEST VOLUME SURGES:\")\n",
    "    display(biggest_surges[['Date', 'Stock', 'Volume_Ratio', 'Total_Day_Volume']].round(2))\n",
    "    \n",
    "    # Show new brokers\n",
    "    new_brokers = results[results['New_Broker']].sort_values('Volume', ascending=False)\n",
    "    if not new_brokers.empty:\n",
    "        print(f\"\\nüÜï NEW BROKERS IN SURGES:\")\n",
    "        display(new_brokers[['Date', 'Stock', 'Broker', 'Side', 'Volume', 'Broker_Percentage']].head(10).round(2))\n",
    "        \n",
    "        # Visualization\n",
    "        fig = px.scatter(new_brokers.head(20), \n",
    "                        x='Date', y='Volume', \n",
    "                        color='Stock', size='Broker_Percentage',\n",
    "                        title='New Broker Activity During Volume Surges',\n",
    "                        hover_data=['Broker', 'Side'])\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No new brokers detected in volume surges\")\n",
    "    \n",
    "    # Show top contributing brokers\n",
    "    top_contributors = results.groupby(['Broker', 'Side'])['Volume'].sum().reset_index().sort_values('Volume', ascending=False)\n",
    "    print(f\"\\nüìä TOP BROKERS IN VOLUME SURGES:\")\n",
    "    display(top_contributors.head(10))\n",
    "\n",
    "# Example usage (uncomment to run with your data)\n",
    "# if not df.empty:\n",
    "#     display_volume_surge_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f90fd",
   "metadata": {},
   "source": [
    "## üí∞ 4. Aggressive Buying Price Analysis\n",
    "\n",
    "**What it detects:** Brokers consistently buying at higher prices to drive market up\n",
    "**Why it matters:** May indicate artificial price pumping or manipulation\n",
    "**Analysis:** Compares broker buy prices vs average market price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_aggressive_buying(df, stock_symbol=None, timeframe='daily', aggressiveness_threshold=5):\n",
    "    \"\"\"\n",
    "    Analyze aggressive buying behavior (buying at consistently higher prices)\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    # Filter data\n",
    "    if stock_symbol:\n",
    "        stock_data = df[df['Stock Symbol'] == stock_symbol]\n",
    "    else:\n",
    "        stock_data = df\n",
    "    \n",
    "    stock_data = get_timeframe_data(stock_data, timeframe)\n",
    "    \n",
    "    if stock_data.empty:\n",
    "        return pd.DataFrame(), {}\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for symbol in stock_data['Stock Symbol'].unique():\n",
    "        symbol_data = stock_data[stock_data['Stock Symbol'] == symbol].copy()\n",
    "        \n",
    "        # Calculate daily average price for the stock\n",
    "        daily_avg_price = symbol_data.groupby('Date')['Rate (Rs)'].mean().reset_index()\n",
    "        daily_avg_price.columns = ['Date', 'Market_Avg_Price']\n",
    "        \n",
    "        # Merge with original data\n",
    "        symbol_data = symbol_data.merge(daily_avg_price, on='Date')\n",
    "        \n",
    "        # Analyze broker buying behavior\n",
    "        broker_analysis = symbol_data.groupby(['Buyer', 'Date']).agg({\n",
    "            'Rate (Rs)': ['mean', 'count'],\n",
    "            'Quantity': 'sum',\n",
    "            'Market_Avg_Price': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        broker_analysis.columns = ['Broker', 'Date', 'Avg_Buy_Price', 'Trade_Count', 'Volume', 'Market_Avg_Price']\n",
    "        broker_analysis['Stock'] = symbol\n",
    "        broker_analysis['Price_Premium'] = ((broker_analysis['Avg_Buy_Price'] - broker_analysis['Market_Avg_Price']) / broker_analysis['Market_Avg_Price']) * 100\n",
    "        \n",
    "        # Flag aggressive buyers (consistently buying above market price)\n",
    "        broker_summary = broker_analysis.groupby('Broker').agg({\n",
    "            'Price_Premium': ['mean', 'std', 'count'],\n",
    "            'Volume': 'sum',\n",
    "            'Trade_Count': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        broker_summary.columns = ['Broker', 'Avg_Price_Premium', 'Price_Premium_Std', 'Trading_Days', 'Total_Volume', 'Total_Trades']\n",
    "        broker_summary['Stock'] = symbol\n",
    "        broker_summary['Aggressive'] = (broker_summary['Avg_Price_Premium'] >= aggressiveness_threshold) & (broker_summary['Trading_Days'] >= 2)\n",
    "        \n",
    "        results.append(broker_summary)\n",
    "    \n",
    "    if results:\n",
    "        final_results = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        summary = {\n",
    "            'aggressive_brokers': len(final_results[final_results['Aggressive']]),\n",
    "            'avg_price_premium': final_results['Avg_Price_Premium'].mean(),\n",
    "            'max_price_premium': final_results['Avg_Price_Premium'].max(),\n",
    "            'total_brokers_analyzed': len(final_results)\n",
    "        }\n",
    "        \n",
    "        return final_results, summary\n",
    "    \n",
    "    return pd.DataFrame(), {}\n",
    "\n",
    "def display_aggressive_buying_analysis(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Display aggressive buying analysis with visualizations\n",
    "    \"\"\"\n",
    "    results, summary = analyze_aggressive_buying(df, stock_symbol, timeframe)\n",
    "    \n",
    "    if results.empty:\n",
    "        print(\"‚ùå No aggressive buying data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üí∞ AGGRESSIVE BUYING ANALYSIS - {timeframe.upper()}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üö® Aggressive Brokers: {summary['aggressive_brokers']}\")\n",
    "    print(f\"üìä Average Price Premium: {summary['avg_price_premium']:.2f}%\")\n",
    "    print(f\"üìà Maximum Price Premium: {summary['max_price_premium']:.2f}%\")\n",
    "    print(f\"üìä Total Brokers Analyzed: {summary['total_brokers_analyzed']}\")\n",
    "    \n",
    "    # Show aggressive brokers\n",
    "    aggressive_brokers = results[results['Aggressive']].sort_values('Avg_Price_Premium', ascending=False)\n",
    "    if not aggressive_brokers.empty:\n",
    "        print(f\"\\nüö® AGGRESSIVE BUYERS (>5% price premium):\")\n",
    "        display(aggressive_brokers[['Stock', 'Broker', 'Avg_Price_Premium', 'Total_Volume', 'Trading_Days']].round(2))\n",
    "        \n",
    "        # Visualization\n",
    "        fig = px.scatter(aggressive_brokers, \n",
    "                        x='Total_Volume', y='Avg_Price_Premium',\n",
    "                        color='Stock', size='Trading_Days',\n",
    "                        title='Aggressive Buying Behavior - Volume vs Price Premium',\n",
    "                        hover_data=['Broker'])\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No aggressive buying behavior detected\")\n",
    "    \n",
    "    # Show top price premium brokers\n",
    "    top_premium = results.sort_values('Avg_Price_Premium', ascending=False).head(10)\n",
    "    print(f\"\\nüìä TOP PRICE PREMIUM BROKERS:\")\n",
    "    display(top_premium[['Stock', 'Broker', 'Avg_Price_Premium', 'Total_Volume', 'Trading_Days']].round(2))\n",
    "    \n",
    "    # Price premium distribution\n",
    "    fig = px.histogram(results, x='Avg_Price_Premium', \n",
    "                      title='Distribution of Broker Price Premiums',\n",
    "                      labels={'Avg_Price_Premium': 'Average Price Premium (%)'})\n",
    "    fig.show()\n",
    "\n",
    "# Example usage (uncomment to run with your data)\n",
    "# if not df.empty:\n",
    "#     display_aggressive_buying_analysis(df, timeframe='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886ffc9",
   "metadata": {},
   "source": [
    "## üìã 5. Net Holdings & Share Turnover Analysis\n",
    "\n",
    "**What it shows:** Broker net positions and overall share trading activity\n",
    "**Why it matters:** Helps understand broker strategies and market liquidity\n",
    "**Analysis:** Net buying/selling per broker, total share turnover, market participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_net_holdings(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Analyze net holdings and share turnover\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}\n",
    "    \n",
    "    # Filter data\n",
    "    if stock_symbol:\n",
    "        stock_data = df[df['Stock Symbol'] == stock_symbol]\n",
    "    else:\n",
    "        stock_data = df\n",
    "    \n",
    "    stock_data = get_timeframe_data(stock_data, timeframe)\n",
    "    \n",
    "    if stock_data.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame(), {}\n",
    "    \n",
    "    # Broker net position analysis\n",
    "    broker_positions = []\n",
    "    \n",
    "    for symbol in stock_data['Stock Symbol'].unique():\n",
    "        symbol_data = stock_data[stock_data['Stock Symbol'] == symbol]\n",
    "        \n",
    "        # Calculate buy positions\n",
    "        buy_positions = symbol_data.groupby('Buyer').agg({\n",
    "            'Quantity': 'sum',\n",
    "            'Amount (Rs)': 'sum',\n",
    "            'Rate (Rs)': 'mean'\n",
    "        }).reset_index()\n",
    "        buy_positions.columns = ['Broker', 'Buy_Volume', 'Buy_Amount', 'Avg_Buy_Price']\n",
    "        \n",
    "        # Calculate sell positions\n",
    "        sell_positions = symbol_data.groupby('Seller').agg({\n",
    "            'Quantity': 'sum',\n",
    "            'Amount (Rs)': 'sum',\n",
    "            'Rate (Rs)': 'mean'\n",
    "        }).reset_index()\n",
    "        sell_positions.columns = ['Broker', 'Sell_Volume', 'Sell_Amount', 'Avg_Sell_Price']\n",
    "        \n",
    "        # Merge buy and sell positions\n",
    "        all_brokers = set(buy_positions['Broker'].tolist() + sell_positions['Broker'].tolist())\n",
    "        \n",
    "        net_positions = []\n",
    "        for broker in all_brokers:\n",
    "            buy_vol = buy_positions[buy_positions['Broker'] == broker]['Buy_Volume'].sum()\n",
    "            sell_vol = sell_positions[sell_positions['Broker'] == broker]['Sell_Volume'].sum()\n",
    "            buy_amt = buy_positions[buy_positions['Broker'] == broker]['Buy_Amount'].sum()\n",
    "            sell_amt = sell_positions[sell_positions['Broker'] == broker]['Sell_Amount'].sum()\n",
    "            \n",
    "            avg_buy_price = buy_positions[buy_positions['Broker'] == broker]['Avg_Buy_Price'].mean()\n",
    "            avg_sell_price = sell_positions[sell_positions['Broker'] == broker]['Avg_Sell_Price'].mean()\n",
    "            \n",
    "            net_positions.append({\n",
    "                'Broker': broker,\n",
    "                'Stock': symbol,\n",
    "                'Buy_Volume': buy_vol,\n",
    "                'Sell_Volume': sell_vol,\n",
    "                'Net_Volume': buy_vol - sell_vol,\n",
    "                'Buy_Amount': buy_amt,\n",
    "                'Sell_Amount': sell_amt,\n",
    "                'Net_Amount': buy_amt - sell_amt,\n",
    "                'Avg_Buy_Price': avg_buy_price if not pd.isna(avg_buy_price) else 0,\n",
    "                'Avg_Sell_Price': avg_sell_price if not pd.isna(avg_sell_price) else 0,\n",
    "                'Total_Volume': buy_vol + sell_vol,\n",
    "                'Position_Type': 'Net_Buyer' if buy_vol > sell_vol else 'Net_Seller' if sell_vol > buy_vol else 'Balanced'\n",
    "            })\n",
    "        \n",
    "        broker_positions.extend(net_positions)\n",
    "    \n",
    "    # Share turnover analysis\n",
    "    share_turnover = stock_data.groupby('Stock Symbol').agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Amount (Rs)': 'sum',\n",
    "        'Rate (Rs)': ['mean', 'min', 'max', 'std'],\n",
    "        'Contract No.': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    share_turnover.columns = ['Stock', 'Total_Volume', 'Total_Amount', 'Avg_Price', 'Min_Price', 'Max_Price', 'Price_Volatility', 'Total_Trades']\n",
    "    share_turnover['Price_Range'] = share_turnover['Max_Price'] - share_turnover['Min_Price']\n",
    "    share_turnover['Price_Range_Pct'] = (share_turnover['Price_Range'] / share_turnover['Avg_Price']) * 100\n",
    "    \n",
    "    # Summary statistics\n",
    "    broker_df = pd.DataFrame(broker_positions)\n",
    "    summary = {\n",
    "        'total_brokers': len(broker_df['Broker'].unique()) if not broker_df.empty else 0,\n",
    "        'net_buyers': len(broker_df[broker_df['Position_Type'] == 'Net_Buyer']) if not broker_df.empty else 0,\n",
    "        'net_sellers': len(broker_df[broker_df['Position_Type'] == 'Net_Seller']) if not broker_df.empty else 0,\n",
    "        'balanced_brokers': len(broker_df[broker_df['Position_Type'] == 'Balanced']) if not broker_df.empty else 0,\n",
    "        'total_market_volume': share_turnover['Total_Volume'].sum() if not share_turnover.empty else 0,\n",
    "        'avg_price_volatility': share_turnover['Price_Range_Pct'].mean() if not share_turnover.empty else 0\n",
    "    }\n",
    "    \n",
    "    return broker_df, share_turnover, summary\n",
    "\n",
    "def display_net_holdings_analysis(df, stock_symbol=None, timeframe='daily'):\n",
    "    \"\"\"\n",
    "    Display net holdings and turnover analysis\n",
    "    \"\"\"\n",
    "    broker_positions, share_turnover, summary = analyze_net_holdings(df, stock_symbol, timeframe)\n",
    "    \n",
    "    if broker_positions.empty:\n",
    "        print(\"‚ùå No holdings data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìã NET HOLDINGS & TURNOVER ANALYSIS - {timeframe.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üë• Total Brokers: {summary['total_brokers']}\")\n",
    "    print(f\"üìà Net Buyers: {summary['net_buyers']}\")\n",
    "    print(f\"üìâ Net Sellers: {summary['net_sellers']}\")\n",
    "    print(f\"‚öñÔ∏è Balanced Brokers: {summary['balanced_brokers']}\")\n",
    "    print(f\"üìä Total Market Volume: {summary['total_market_volume']:,.0f}\")\n",
    "    print(f\"üìä Average Price Volatility: {summary['avg_price_volatility']:.2f}%\")\n",
    "    \n",
    "    # Top net buyers\n",
    "    top_buyers = broker_positions[broker_positions['Position_Type'] == 'Net_Buyer'].sort_values('Net_Volume', ascending=False)\n",
    "    if not top_buyers.empty:\n",
    "        print(f\"\\nüìà TOP NET BUYERS:\")\n",
    "        display(top_buyers[['Stock', 'Broker', 'Net_Volume', 'Net_Amount', 'Total_Volume']].head(10))\n",
    "        \n",
    "        # Visualization for net buyers\n",
    "        fig = px.bar(top_buyers.head(15), \n",
    "                    x='Broker', y='Net_Volume', \n",
    "                    color='Stock',\n",
    "                    title='Top Net Buyers by Volume')\n",
    "        fig.update_xaxes(tickangle=45)\n",
    "        fig.show()\n",
    "    \n",
    "    # Top net sellers\n",
    "    top_sellers = broker_positions[broker_positions['Position_Type'] == 'Net_Seller'].sort_values('Net_Volume')\n",
    "    if not top_sellers.empty:\n",
    "        print(f\"\\nüìâ TOP NET SELLERS:\")\n",
    "        display(top_sellers[['Stock', 'Broker', 'Net_Volume', 'Net_Amount', 'Total_Volume']].head(10))\n",
    "    \n",
    "    # Share turnover analysis\n",
    "    if not share_turnover.empty:\n",
    "        print(f\"\\nüìä SHARE TURNOVER ANALYSIS:\")\n",
    "        share_turnover_display = share_turnover.sort_values('Total_Volume', ascending=False)\n",
    "        display(share_turnover_display[['Stock', 'Total_Volume', 'Total_Amount', 'Avg_Price', 'Price_Range_Pct', 'Total_Trades']].round(2))\n",
    "        \n",
    "        # Visualization for share turnover\n",
    "        fig = make_subplots(rows=2, cols=1, \n",
    "                           subplot_titles=['Volume by Stock', 'Price Volatility by Stock'])\n",
    "        \n",
    "        fig.add_trace(go.Bar(x=share_turnover_display['Stock'], y=share_turnover_display['Total_Volume'], \n",
    "                            name='Volume'), row=1, col=1)\n",
    "        fig.add_trace(go.Bar(x=share_turnover_display['Stock'], y=share_turnover_display['Price_Range_Pct'], \n",
    "                            name='Price Volatility %'), row=2, col=1)\n",
    "        \n",
    "        fig.update_layout(title='Share Trading Summary', showlegend=False)\n",
    "        fig.show()\n",
    "    \n",
    "    # Broker activity distribution\n",
    "    activity_dist = broker_positions['Position_Type'].value_counts()\n",
    "    fig = px.pie(values=activity_dist.values, names=activity_dist.index, \n",
    "                title='Broker Position Distribution')\n",
    "    fig.show()\n",
    "\n",
    "# Example usage (uncomment to run with your data)\n",
    "# if not df.empty:\n",
    "#     display_net_holdings_analysis(df, timeframe='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df061d",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Interactive Analysis Dashboard\n",
    "\n",
    "**Easy-to-use controls for non-technical users**\n",
    "Select your preferred stock and timeframe to run all analyses automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_dashboard(df):\n",
    "    \"\"\"\n",
    "    Create an interactive dashboard for easy analysis\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"‚ùå No data available for dashboard\")\n",
    "        return\n",
    "    \n",
    "    # Get available stocks\n",
    "    available_stocks = ['All Stocks'] + sorted(df['Stock Symbol'].unique().tolist())\n",
    "    \n",
    "    # Create widgets\n",
    "    stock_dropdown = widgets.Dropdown(\n",
    "        options=available_stocks,\n",
    "        value='All Stocks',\n",
    "        description='Stock:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    timeframe_dropdown = widgets.Dropdown(\n",
    "        options=['daily', 'weekly', '15days', 'monthly', 'quarterly', 'yearly'],\n",
    "        value='daily',\n",
    "        description='Timeframe:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    analysis_type = widgets.Dropdown(\n",
    "        options=[\n",
    "            'All Analyses',\n",
    "            'Broker Dominance',\n",
    "            'Wash Trading',\n",
    "            'Volume Surge',\n",
    "            'Aggressive Buying',\n",
    "            'Net Holdings'\n",
    "        ],\n",
    "        value='All Analyses',\n",
    "        description='Analysis:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    run_button = widgets.Button(\n",
    "        description='üîç Run Analysis',\n",
    "        button_style='success',\n",
    "        style={'font_weight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def run_analysis(button):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            \n",
    "            selected_stock = None if stock_dropdown.value == 'All Stocks' else stock_dropdown.value\n",
    "            selected_timeframe = timeframe_dropdown.value\n",
    "            selected_analysis = analysis_type.value\n",
    "            \n",
    "            print(f\"üîç Running {selected_analysis} for {stock_dropdown.value} - {selected_timeframe}\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            try:\n",
    "                if selected_analysis == 'All Analyses' or selected_analysis == 'Broker Dominance':\n",
    "                    display_dominance_analysis(df, selected_stock, selected_timeframe)\n",
    "                    print(\"\\\\n\" + \"=\"*70 + \"\\\\n\")\n",
    "                \n",
    "                if selected_analysis == 'All Analyses' or selected_analysis == 'Wash Trading':\n",
    "                    display_wash_trading_analysis(df, selected_stock, selected_timeframe)\n",
    "                    print(\"\\\\n\" + \"=\"*70 + \"\\\\n\")\n",
    "                \n",
    "                if selected_analysis == 'All Analyses' or selected_analysis == 'Volume Surge':\n",
    "                    display_volume_surge_analysis(df, selected_stock)\n",
    "                    print(\"\\\\n\" + \"=\"*70 + \"\\\\n\")\n",
    "                \n",
    "                if selected_analysis == 'All Analyses' or selected_analysis == 'Aggressive Buying':\n",
    "                    display_aggressive_buying_analysis(df, selected_stock, selected_timeframe)\n",
    "                    print(\"\\\\n\" + \"=\"*70 + \"\\\\n\")\n",
    "                \n",
    "                if selected_analysis == 'All Analyses' or selected_analysis == 'Net Holdings':\n",
    "                    display_net_holdings_analysis(df, selected_stock, selected_timeframe)\n",
    "                \n",
    "                print(\"\\\\n‚úÖ Analysis completed!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error during analysis: {str(e)}\")\n",
    "    \n",
    "    run_button.on_click(run_analysis)\n",
    "    \n",
    "    # Create layout\n",
    "    controls = widgets.HBox([stock_dropdown, timeframe_dropdown, analysis_type, run_button])\n",
    "    dashboard = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üéõÔ∏è NEPSE Floor Sheet Analysis Dashboard</h3>\"),\n",
    "        controls,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# Create and display the dashboard\n",
    "if not df.empty:\n",
    "    dashboard = create_interactive_dashboard(df)\n",
    "    display(dashboard)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"üéØ QUICK START GUIDE:\")\n",
    "    print(\"1. Select a stock from the dropdown (or 'All Stocks' for market-wide analysis)\")\n",
    "    print(\"2. Choose your preferred timeframe\")\n",
    "    print(\"3. Pick a specific analysis or run 'All Analyses'\")\n",
    "    print(\"4. Click 'Run Analysis' to see results\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ùå No data available. Please load floor sheet data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788f032",
   "metadata": {},
   "source": [
    "## üìä Summary & Key Insights\n",
    "\n",
    "### üéØ What This Analysis Tells You:\n",
    "\n",
    "1. **üö® Broker Dominance** - Identifies potential market manipulation when single brokers control large volumes\n",
    "2. **üîÑ Wash Trading** - Detects suspicious same-broker trades that may indicate illegal activity  \n",
    "3. **üìà Volume Surges** - Highlights unusual trading spikes and responsible brokers\n",
    "4. **üí∞ Aggressive Buying** - Finds brokers consistently buying at premium prices\n",
    "5. **üìã Net Holdings** - Shows overall broker positions and market participation\n",
    "\n",
    "### üîç How to Interpret Results:\n",
    "\n",
    "- **Red Flags:** High broker dominance (>60%), same-broker trades, sudden volume spikes\n",
    "- **Green Flags:** Balanced broker participation, normal volume patterns, fair pricing\n",
    "- **Watch List:** New brokers with high activity, repetitive trading patterns\n",
    "\n",
    "### ‚ö†Ô∏è Important Notes:\n",
    "\n",
    "- This analysis is for educational and research purposes\n",
    "- Always consider market context and fundamentals\n",
    "- Suspicious patterns don't always indicate wrongdoing\n",
    "- Consult financial professionals for investment decisions\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Analysis Complete! Use the interactive dashboard above to explore different stocks and timeframes.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
