name: ðŸ“Š Daily NEPSE Floor Sheet Scraper

on:
  schedule:
    # Run daily at 4:00 PM Nepal Time (10:30 AM UTC)
    - cron: "30 10 * * *"
  workflow_dispatch: # Allow manual triggering

permissions:
  contents: write
  actions: read

jobs:
  scrape-floorsheet:
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ”„ Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: ðŸ“¦ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ðŸŒ Setup Chrome Browser
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: ðŸŒ Setup ChromeDriver
        uses: nanasess/setup-chromedriver@v2

      - name: ðŸ–¥ï¸ Setup Virtual Display
        run: |
          # Install and start Xvfb for headless browser support
          sudo apt-get update
          sudo apt-get install -y xvfb
          # Start Xvfb on display :99
          Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
          # Wait for Xvfb to start
          sleep 3

      - name: ðŸ§ª Test Chrome Setup
        run: |
          echo "Testing Chrome and ChromeDriver setup..."
          echo "Chrome version:"
          google-chrome --version
          echo "ChromeDriver version:"
          chromedriver --version
          echo "ChromeDriver location:"
          which chromedriver
          
          # Test basic Chrome functionality
          python -c "
          from selenium import webdriver
          from selenium.webdriver.chrome.options import Options
          
          options = Options()
          options.add_argument('--headless=new')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          options.add_argument('--disable-gpu')
          options.add_argument('--remote-debugging-port=9222')
          
          try:
              driver = webdriver.Chrome(options=options)
              driver.get('https://www.google.com')
              print('âœ… Chrome setup successful!')
              print(f'Page title: {driver.title}')
              driver.quit()
          except Exception as e:
              print(f'âŒ Chrome setup failed: {e}')
              exit(1)
          "
        env:
          DISPLAY: :99

      - name: ðŸ“Š Run Floor Sheet Scraper
        run: |
          echo "Starting NEPSE Floor Sheet Scraper..."
          python scrape_floorsheet.py
        env:
          DISPLAY: :99
          CHROME_BIN: /usr/bin/google-chrome

      - name: ðŸ“ Check for New Data
        id: check-data
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "âœ… New data detected"
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸ No new data found"
          fi

      - name: ðŸ’¾ Commit and Push New Data
        if: steps.check-data.outputs.has_changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          git commit -m "ðŸ“Š Daily floor sheet data update - $(date +'%Y-%m-%d')"
          git push

      - name: ðŸ“ˆ Generate Summary Report
        if: steps.check-data.outputs.has_changes == 'true'
        run: |
          echo "## ðŸ“Š Daily NEPSE Data Update - $(date +'%Y-%m-%d')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“ Files Updated:" >> $GITHUB_STEP_SUMMARY
          ls -la data/ | tail -n +2 | while read -r line; do
            echo "- $line" >> $GITHUB_STEP_SUMMARY
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“ˆ Latest Data:" >> $GITHUB_STEP_SUMMARY
          LATEST_FILE=$(ls -t data/*.csv | head -n 1)
          if [ -f "$LATEST_FILE" ]; then
            echo "**File:** $(basename $LATEST_FILE)" >> $GITHUB_STEP_SUMMARY
            echo "**Records:** $(tail -n +2 $LATEST_FILE | wc -l)" >> $GITHUB_STEP_SUMMARY
            echo "**Size:** $(ls -lh $LATEST_FILE | awk '{print $5}')" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Data successfully scraped and committed to repository" >> $GITHUB_STEP_SUMMARY

      - name: ðŸš¨ Notify on Failure
        if: failure()
        run: |
          echo "## âŒ NEPSE Scraper Failed - $(date +'%Y-%m-%d')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The daily floor sheet scraping job failed. Please check the logs for details." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Possible causes:**" >> $GITHUB_STEP_SUMMARY
          echo "- NEPSE website is down or changed structure" >> $GITHUB_STEP_SUMMARY
          echo "- ChromeDriver compatibility issues" >> $GITHUB_STEP_SUMMARY
          echo "- Network connectivity problems" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next steps:**" >> $GITHUB_STEP_SUMMARY
          echo "1. Check NEPSE website accessibility" >> $GITHUB_STEP_SUMMARY
          echo "2. Review scraper logs" >> $GITHUB_STEP_SUMMARY
          echo "3. Update scraper if website structure changed" >> $GITHUB_STEP_SUMMARY
